{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/peppe/01_Study/01_University/Semester/2/Intro_to_ML/Project/Code/models_methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "\n",
    "from utility.smooth_cross_entropy import smooth_crossentropy\n",
    "from data.cifar import Cifar\n",
    "from utility.log import Log\n",
    "from utility.initialize import initialize\n",
    "from utility.step_lr import StepLR\n",
    "from utility.bypass_bn import enable_running_stats, disable_running_stats\n",
    "from torchvision.models import efficientnet_b0\n",
    "\n",
    "import sys; sys.path.append(\"..\")\n",
    "from methods.SAM.sam import SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(weights=\"Default\"):\n",
    "    model = efficientnet_b0(pretrained=weights)\n",
    "    model.classifier[1] = torch.nn.Linear(1280, 10, bias=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.classifier[1].weight.requires_grad = True\n",
    "    model.classifier[1].bias.requires_grad = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = get_model(weights=\"Default\") # ImageNet1K_V1 weights\n",
    "    log = Log(log_each=10)\n",
    "    base_optimizer = torch.optim.SGD\n",
    "    optimizer = SAM(model.parameters(), \n",
    "                    base_optimizer, \n",
    "                    rho=2, \n",
    "                    adaptive=False, # True if you want to use the Adaptive SAM.\n",
    "                    lr=0.1, momentum=0.9, weight_decay=0.0005)\n",
    "    scheduler = StepLR(optimizer, learning_rate=0.1, total_epochs=1)\n",
    "\n",
    "    initialize(seed=42)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    dataset = Cifar(batch_size=128, # Batch size used in the training and validation loop\n",
    "                    threads=2) # Number of CPU threads for dataloaders\n",
    "\n",
    "    for epoch in range(1):\n",
    "        model.train()\n",
    "        log.train(len_dataset=len(dataset.train))\n",
    "\n",
    "        for batch in dataset.train:\n",
    "            inputs, targets = (b.to(device) for b in batch)\n",
    "\n",
    "            # first forward-backward step\n",
    "            enable_running_stats(model)\n",
    "            predictions = model(inputs)\n",
    "            loss = smooth_crossentropy(predictions, targets, \n",
    "                                       smoothing=0.1) # if smoothing=0.0, it's the same as nn.CrossEntropyLoss\n",
    "            loss.mean().backward()\n",
    "            optimizer.first_step(zero_grad=True)\n",
    "\n",
    "            # second forward-backward step\n",
    "            disable_running_stats(model)\n",
    "            smooth_crossentropy(model(inputs), targets, smoothing=0.1).mean().backward()\n",
    "            optimizer.second_step(zero_grad=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                correct = torch.argmax(predictions.data, 1) == targets\n",
    "                log(model, loss.cpu(), correct.cpu(), scheduler.lr())\n",
    "                scheduler(epoch)\n",
    "\n",
    "        model.eval()\n",
    "        log.eval(len_dataset=len(dataset.test))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in dataset.test:\n",
    "                inputs, targets = (b.to(device) for b in batch)\n",
    "\n",
    "                predictions = model(inputs)\n",
    "                loss = smooth_crossentropy(predictions, targets)\n",
    "                correct = torch.argmax(predictions, 1) == targets\n",
    "                log(model, loss.cpu(), correct.cpu())\n",
    "\n",
    "    log.flush()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
