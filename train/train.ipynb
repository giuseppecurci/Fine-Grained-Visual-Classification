{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/peppe/01_Study/01_University/Semester/2/Intro_to_ML/Project/Code/models_methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility.bypass_bn import enable_running_stats, disable_running_stats\n",
    "from utility.initialize import initialize\n",
    "from utility.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(model, data_loader, optimizer, loss_fn, device, SAM=False):\n",
    "    samples = 0.0\n",
    "    cumulative_loss = 0.0\n",
    "    cumulative_accuracy = 0.0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # first forward-backward step\n",
    "        if SAM:        \n",
    "            enable_running_stats(model) # disable batch norm running stats\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.mean().backward()\n",
    "        \n",
    "        if SAM:\n",
    "            optimizer.first_step(zero_grad=True)\n",
    "            # second forward-backward step\n",
    "            disable_running_stats(model)\n",
    "            loss = loss_fn(model(inputs), targets)\n",
    "            loss.mean().backward()\n",
    "            optimizer.second_step(zero_grad=True)\n",
    "        else:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        samples += inputs.shape[0]\n",
    "        cumulative_loss += loss.item()\n",
    "        _, predicted = outputs.max(dim=1)\n",
    "\n",
    "        cumulative_accuracy += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return cumulative_loss / samples, cumulative_accuracy / samples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, data_loader, loss_fn, device):\n",
    "    samples = 0.\n",
    "    cumulative_loss = 0.\n",
    "    cumulative_accuracy = 0.\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            samples += inputs.shape[0]\n",
    "            cumulative_loss += loss.item() \n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            cumulative_accuracy += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return cumulative_loss / samples, cumulative_accuracy / samples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard logging utilities\n",
    "def log_values(writer, step, loss, accuracy, prefix):\n",
    "    writer.add_scalar(f\"{prefix}/loss\", loss, step)\n",
    "    writer.add_scalar(f\"{prefix}/accuracy\", accuracy, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model,\n",
    "         optimizer,\n",
    "         loss_fn,\n",
    "         data_loaders: dict,\n",
    "         train_step: callable,\n",
    "         test_step: callable,\n",
    "         device,\n",
    "         epochs=10,\n",
    "         exp_name=None,\n",
    "         exp_path=\"Code/experiments/\",\n",
    "         verbose=True,\n",
    "         use_early_stopping=True,\n",
    "         patience=5,\n",
    "         delta=1e-3,\n",
    "         scheduler=None):\n",
    "    \n",
    "    assert os.path.exists(f\"{exp_path + exp_name}\"), \"Experiment path does not exist\"\n",
    "    # Create a logger for the experiment\n",
    "    writer = SummaryWriter(log_dir=f\"{exp_path + exp_name}\")\n",
    "\n",
    "    initialize(seed=42)\n",
    "\n",
    "    if use_early_stopping:\n",
    "        early_stopping = EarlyStopping(patience=patience, \n",
    "                                       delta=delta)\n",
    "        \n",
    "    model.to(device)\n",
    "    \n",
    "    # Computes evaluation results before training\n",
    "    print(\"Before training:\")\n",
    "    train_loss, train_accuracy = test_step(model, data_loaders[\"train_loader\"], loss_fn,device=device)\n",
    "    val_loss, val_accuracy = test_step(model, data_loaders[\"val_loader\"], loss_fn,device=device)\n",
    "    test_loss, test_accuracy = test_step(model, data_loaders[\"test_loader\"], loss_fn,device=device)\n",
    "    \n",
    "    # Log to TensorBoard\n",
    "    log_values(writer, -1, train_loss, train_accuracy, \"Train\")\n",
    "    log_values(writer, -1, val_loss, val_accuracy, \"Validation\")\n",
    "    log_values(writer, -1, test_loss, test_accuracy, \"Test\")\n",
    "\n",
    "    print(f\"\\tTraining loss {train_loss:.5f}, Training accuracy {train_accuracy:.2f}\")\n",
    "    print(f\"\\tValidation loss {val_loss:.5f}, Validation accuracy {val_accuracy:.2f}\")\n",
    "    print(f\"\\tTest loss {test_loss:.5f}, Test accuracy {test_accuracy:.2f}\")\n",
    "    print(\"-----------------------------------------------------\")\n",
    "    \n",
    "    pbar = tqdm(range(epochs), desc=\"Training\")\n",
    "    for e in pbar:\n",
    "        train_loss, train_accuracy = train_step(model, data_loaders[\"train_loader\"], optimizer, loss_fn, device=device)\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        val_loss, val_accuracy = test_step(model, data_loaders[\"val_loader\"], loss_fn,device=device)\n",
    "        if verbose:\n",
    "            print(f\"Epoch: {e + 1}\")\n",
    "            print(f\"\\tTraining loss {train_loss:.5f}, Training accuracy {train_accuracy:.2f}\")\n",
    "            print(f\"\\tValidation loss {val_loss:.5f}, Validation accuracy {val_accuracy:.2f}\")\n",
    "            print(\"-----------------------------------------------------\")\n",
    "        \n",
    "        # Logs to TensorBoard\n",
    "        log_values(writer, e, train_loss, train_accuracy, \"Train\")\n",
    "        log_values(writer, e, val_loss, val_accuracy, \"Validation\")\n",
    "\n",
    "        pbar.set_postfix(train_loss=train_loss, train_accuracy=train_accuracy, val_loss=val_loss, val_accuracy=val_accuracy)\n",
    "\n",
    "        if use_early_stopping:\n",
    "            early_stopping(val_loss, model)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "    # Compute final evaluation results\n",
    "    print(\"After training:\")\n",
    "    train_loss, train_accuracy = test_step(model, data_loaders[\"train_loader\"], loss_fn,device=device)\n",
    "    val_loss, val_accuracy = test_step(model, data_loaders[\"val_loader\"], loss_fn,device=device)\n",
    "    test_loss, test_accuracy = test_step(model, data_loaders[\"test_loader\"], loss_fn,device=device)\n",
    "\n",
    "    # Log to TensorBoard\n",
    "    log_values(writer, epochs + 1, train_loss, train_accuracy, \"Train\")\n",
    "    log_values(writer, epochs + 1, val_loss, val_accuracy, \"Validation\")\n",
    "    log_values(writer, epochs + 1, test_loss, test_accuracy, \"Test\")\n",
    "\n",
    "    print(f\"\\tTraining loss {train_loss:.5f}, Training accuracy {train_accuracy:.2f}\")\n",
    "    print(f\"\\tValidation loss {val_loss:.5f}, Validation accuracy {val_accuracy:.2f}\")\n",
    "    print(f\"\\tTest loss {test_loss:.5f}, Test accuracy {test_accuracy:.2f}\")\n",
    "    print(\"-----------------------------------------------------\")\n",
    "\n",
    "    # Closes the logger\n",
    "    writer.close()\n",
    "\n",
    "    # Let's return the net\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize with tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=runs3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
